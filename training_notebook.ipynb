{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ce4254",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccc088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n",
      "PyTorch version: 2.9.1+cu128\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import random_split\n",
    "from torchaudio.datasets import LJSPEECH\n",
    "\n",
    "# Import from our modules\n",
    "from models import MLP, CNN, RNN_LSTM, RNN_GRU, RNN_BiLSTM\n",
    "from data import TextEncoder, FeatureExtractor, create_dataloaders, greedy_decode\n",
    "from trainer import TrainingConfig, Trainer, CNNTrainer, ModelComparator\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0090008",
   "metadata": {},
   "source": [
    "## 2. Setup Device and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f0af5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Loading LJSPEECH dataset...\n",
      "Total samples: 13100\n",
      "Train set: 11790 | Test set: 1310\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# crate dir for data if not exists\n",
    "import os\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading LJSPEECH dataset...\")\n",
    "dataset = LJSPEECH(root=\"./data\", download=True)\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "\n",
    "# Split into train/test\n",
    "train_len = int(len(dataset) * 0.9)\n",
    "test_len = len(dataset) - train_len\n",
    "train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "print(f\"Train set: {train_len} | Test set: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de4e7e3",
   "metadata": {},
   "source": [
    "## 3. Initialize Text Encoder and Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8d82ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 39\n",
      "Character set: _-!'(),.:;? abcdefghijklmnopqrstuvwxyz\n",
      "âœ“ Text encoder and feature extractors ready\n"
     ]
    }
   ],
   "source": [
    "# Text encoder\n",
    "text_encoder = TextEncoder()\n",
    "print(f\"Number of classes: {text_encoder.num_classes}\")\n",
    "print(f\"Character set: {text_encoder.symbols}\")\n",
    "\n",
    "# Feature extractors\n",
    "feature_extractor_mfcc = FeatureExtractor(feature_type='mfcc', sample_rate=22050)\n",
    "feature_extractor_mel = FeatureExtractor(feature_type='mel', sample_rate=22050)\n",
    "\n",
    "print(\"âœ“ Text encoder and feature extractors ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f257c",
   "metadata": {},
   "source": [
    "## 4. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ea03e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MFCC dataloaders...\n",
      "âœ“ MFCC loaders created (737 train batches)\n",
      "Creating MelSpectrogram dataloaders...\n",
      "âœ“ MelSpectrogram loaders created (737 train batches)\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders for MFCC\n",
    "print(\"Creating MFCC dataloaders...\")\n",
    "train_loader_mfcc, test_loader_mfcc = create_dataloaders(\n",
    "    train_dataset, test_dataset,\n",
    "    feature_extractor_mfcc, text_encoder,\n",
    "    batch_size=16, num_workers=0\n",
    ")\n",
    "print(f\"âœ“ MFCC loaders created ({len(train_loader_mfcc)} train batches)\")\n",
    "\n",
    "# Create dataloaders for MelSpectrogram\n",
    "print(\"Creating MelSpectrogram dataloaders...\")\n",
    "train_loader_mel, test_loader_mel = create_dataloaders(\n",
    "    train_dataset, test_dataset,\n",
    "    feature_extractor_mel, text_encoder,\n",
    "    batch_size=16, num_workers=0\n",
    ")\n",
    "print(f\"âœ“ MelSpectrogram loaders created ({len(train_loader_mel)} train batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c132eda",
   "metadata": {},
   "source": [
    "## 5. Define Decoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89d4aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Decoding function ready\n"
     ]
    }
   ],
   "source": [
    "def decode_fn(log_probs):\n",
    "    \"\"\"Wrapper for greedy decoding.\"\"\"\n",
    "    return greedy_decode(log_probs, text_encoder)\n",
    "\n",
    "print(\"âœ“ Decoding function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63049b2",
   "metadata": {},
   "source": [
    "## 6. Train MLP + MFCC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bca7e3",
   "metadata": {},
   "source": [
    "### Note: Training takes time\n",
    "The models will train for 2 epochs on the LJSPEECH dataset (~13,000 samples). This may take 30+ minutes depending on your hardware. For faster testing, you can:\n",
    "1. Reduce `num_epochs` to 1\n",
    "2. Use a smaller batch size\n",
    "3. Limit the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece57f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING: MLP + MFCC\n",
      "======================================================================\n",
      "======================================================================\n",
      "Training: MLP + MFCC\n",
      "======================================================================\n",
      "Parameters: 43,047\n",
      "Device: cpu\n",
      "  Epoch 1 Batch 50: loss = 12.3322\n",
      "  Epoch 1 Batch 50: loss = 12.3322\n",
      "  Epoch 1 Batch 100: loss = 5.0888\n",
      "  Epoch 1 Batch 100: loss = 5.0888\n",
      "  Epoch 1 Batch 150: loss = 3.2678\n",
      "  Epoch 1 Batch 150: loss = 3.2678\n",
      "  Epoch 1 Batch 200: loss = 3.0670\n",
      "  Epoch 1 Batch 200: loss = 3.0670\n",
      "  Epoch 1 Batch 250: loss = 3.0619\n",
      "  Epoch 1 Batch 250: loss = 3.0619\n",
      "  Epoch 1 Batch 300: loss = 3.0069\n",
      "  Epoch 1 Batch 300: loss = 3.0069\n",
      "  Epoch 1 Batch 350: loss = 3.0596\n",
      "  Epoch 1 Batch 350: loss = 3.0596\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING: MLP + MFCC\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "config = TrainingConfig(\n",
    "    num_epochs=2,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=16,\n",
    "    grad_clip=1.0,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# MLP with MFCC (128 features)\n",
    "model_mlp = MLP(\n",
    "    in_dim=128,\n",
    "    hidden=256,\n",
    "    num_classes=text_encoder.num_classes\n",
    ")\n",
    "\n",
    "trainer_mlp = Trainer(model_mlp, config, blank_idx=0)\n",
    "metrics_mlp = trainer_mlp.train(\n",
    "    train_loader_mfcc,\n",
    "    test_loader_mfcc,\n",
    "    decode_fn,\n",
    "    \"MLP + MFCC\"\n",
    ")\n",
    "trainer_mlp.save(\"mlp_ctc.pth\")\n",
    "\n",
    "print(\"âœ“ MLP model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96706320",
   "metadata": {},
   "source": [
    "## 7. Train CNN + MelSpectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486731d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING: CNN + MelSpectrogram\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model_cnn = CNN(\n",
    "    n_mels=64,\n",
    "    num_classes=text_encoder.num_classes\n",
    ")\n",
    "\n",
    "trainer_cnn = CNNTrainer(model_cnn, config, blank_idx=0)\n",
    "metrics_cnn = trainer_cnn.train(\n",
    "    train_loader_mel,\n",
    "    test_loader_mel,\n",
    "    decode_fn,\n",
    "    \"CNN + MelSpectrogram\"\n",
    ")\n",
    "trainer_cnn.save(\"cnn_mel_ctc.pth\")\n",
    "\n",
    "print(\"âœ“ CNN model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25efd6b",
   "metadata": {},
   "source": [
    "## 8. Train LSTM + MelSpectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef350a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING: LSTM + MelSpectrogram\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model_lstm = RNN_LSTM(\n",
    "    input_dim=64,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    num_classes=text_encoder.num_classes\n",
    ")\n",
    "\n",
    "trainer_lstm = Trainer(model_lstm, config, blank_idx=0)\n",
    "metrics_lstm = trainer_lstm.train(\n",
    "    train_loader_mel,\n",
    "    test_loader_mel,\n",
    "    decode_fn,\n",
    "    \"LSTM + MelSpectrogram\"\n",
    ")\n",
    "trainer_lstm.save(\"lstm_ctc.pth\")\n",
    "\n",
    "print(\"âœ“ LSTM model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919b86e",
   "metadata": {},
   "source": [
    "## 9. Train GRU + MelSpectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING: GRU + MelSpectrogram\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model_gru = RNN_GRU(\n",
    "    input_dim=64,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    num_classes=text_encoder.num_classes\n",
    ")\n",
    "\n",
    "trainer_gru = Trainer(model_gru, config, blank_idx=0)\n",
    "metrics_gru = trainer_gru.train(\n",
    "    train_loader_mel,\n",
    "    test_loader_mel,\n",
    "    decode_fn,\n",
    "    \"GRU + MelSpectrogram\"\n",
    ")\n",
    "trainer_gru.save(\"gru_ctc.pth\")\n",
    "\n",
    "print(\"âœ“ GRU model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49495c65",
   "metadata": {},
   "source": [
    "## 10. Train BiLSTM + MelSpectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING: BiLSTM + MelSpectrogram\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model_bilstm = RNN_BiLSTM(\n",
    "    input_dim=64,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    num_classes=text_encoder.num_classes\n",
    ")\n",
    "\n",
    "trainer_bilstm = Trainer(model_bilstm, config, blank_idx=0)\n",
    "metrics_bilstm = trainer_bilstm.train(\n",
    "    train_loader_mel,\n",
    "    test_loader_mel,\n",
    "    decode_fn,\n",
    "    \"BiLSTM + MelSpectrogram\"\n",
    ")\n",
    "trainer_bilstm.save(\"bilstm_ctc.pth\")\n",
    "\n",
    "print(\"âœ“ BiLSTM model training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380d551",
   "metadata": {},
   "source": [
    "## 11. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize comparator\n",
    "comparator = ModelComparator()\n",
    "\n",
    "# Add all results\n",
    "comparator.add_result(\"MLP + MFCC\", metrics_mlp)\n",
    "comparator.add_result(\"CNN + MelSpectrogram\", metrics_cnn)\n",
    "comparator.add_result(\"LSTM + MelSpectrogram\", metrics_lstm)\n",
    "comparator.add_result(\"GRU + MelSpectrogram\", metrics_gru)\n",
    "comparator.add_result(\"BiLSTM + MelSpectrogram\", metrics_bilstm)\n",
    "\n",
    "# Print comparison\n",
    "comparator.print_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93254163",
   "metadata": {},
   "source": [
    "## 12. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Loss Convergence\n",
    "ax = axes[0, 0]\n",
    "for model_name in [\"MLP + MFCC\", \"CNN + MelSpectrogram\", \"LSTM + MelSpectrogram\", \n",
    "                    \"GRU + MelSpectrogram\", \"BiLSTM + MelSpectrogram\"]:\n",
    "    metrics = comparator.results[model_name]\n",
    "    ax.plot(metrics['epochs'], metrics['train_losses'], marker='o', label=model_name, linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=11)\n",
    "ax.set_ylabel('Training Loss', fontsize=11)\n",
    "ax.set_title('Loss Convergence', fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Training Time per Epoch\n",
    "ax = axes[0, 1]\n",
    "models = [\"MLP\", \"CNN\", \"LSTM\", \"GRU\", \"BiLSTM\"]\n",
    "times_per_epoch = []\n",
    "for model_name in [\"MLP + MFCC\", \"CNN + MelSpectrogram\", \"LSTM + MelSpectrogram\", \n",
    "                    \"GRU + MelSpectrogram\", \"BiLSTM + MelSpectrogram\"]:\n",
    "    metrics = comparator.results[model_name]\n",
    "    avg_time = sum(metrics['train_times']) / len(metrics['train_times']) if metrics['train_times'] else 0\n",
    "    times_per_epoch.append(avg_time)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "bars = ax.bar(models, times_per_epoch, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('Time per Epoch (seconds)', fontsize=11)\n",
    "ax.set_title('Training Speed', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, t in zip(bars, times_per_epoch):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{t:.1f}s', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# 3. Parameter Count\n",
    "ax = axes[1, 0]\n",
    "params_sorted = sorted([\n",
    "    (\"MLP\", comparator.results[\"MLP + MFCC\"]['param_count']),\n",
    "    (\"CNN\", comparator.results[\"CNN + MelSpectrogram\"]['param_count']),\n",
    "    (\"LSTM\", comparator.results[\"LSTM + MelSpectrogram\"]['param_count']),\n",
    "    (\"GRU\", comparator.results[\"GRU + MelSpectrogram\"]['param_count']),\n",
    "    (\"BiLSTM\", comparator.results[\"BiLSTM + MelSpectrogram\"]['param_count']),\n",
    "], key=lambda x: x[1])\n",
    "\n",
    "names, params = zip(*params_sorted)\n",
    "bars = ax.barh(names, params, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Number of Parameters', fontsize=11)\n",
    "ax.set_title('Model Size', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, p in zip(bars, params):\n",
    "    width = bar.get_width()\n",
    "    ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "            f'{p:,.0f}', ha='left', va='center', fontweight='bold', fontsize=9, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "# 4. Summary Statistics Table\n",
    "ax = axes[1, 1]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "# Create table data\n",
    "table_data = []\n",
    "for model_name in [\"MLP + MFCC\", \"CNN + MelSpectrogram\", \"LSTM + MelSpectrogram\", \n",
    "                    \"GRU + MelSpectrogram\", \"BiLSTM + MelSpectrogram\"]:\n",
    "    metrics = comparator.results[model_name]\n",
    "    total_time = sum(metrics['train_times'])\n",
    "    final_loss = metrics['train_losses'][-1] if metrics['train_losses'] else 0\n",
    "    model_short = model_name.split()[0]\n",
    "    table_data.append([\n",
    "        model_short,\n",
    "        f\"{metrics['param_count']:,}\",\n",
    "        f\"{total_time:.1f}s\",\n",
    "        f\"{final_loss:.4f}\"\n",
    "    ])\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=table_data,\n",
    "    colLabels=['Model', 'Parameters', 'Time (2 epochs)', 'Final Loss'],\n",
    "    cellLoc='center',\n",
    "    loc='center',\n",
    "    colWidths=[0.15, 0.25, 0.25, 0.25]\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style header\n",
    "for i in range(4):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Style rows\n",
    "for i in range(1, 6):\n",
    "    for j in range(4):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#f0f0f0')\n",
    "        else:\n",
    "            table[(i, j)].set_facecolor('#ffffff')\n",
    "\n",
    "ax.set_title('Performance Summary', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Comparison visualizations saved to 'model_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d362e61",
   "metadata": {},
   "source": [
    "## 13. Detailed Analysis and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED MODEL ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                        MODEL CHARACTERISTICS                            â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ðŸ“Š MLP + MFCC\n",
    "   â”œâ”€ Architecture: Simple feedforward network\n",
    "   â”œâ”€ Temporal Modeling: None (independent timesteps)\n",
    "   â”œâ”€ Best For: Fast baseline, testing pipeline\n",
    "   â”œâ”€ Pros:\n",
    "   â”‚  âœ“ Very fast training\n",
    "   â”‚  âœ“ Minimal memory usage\n",
    "   â”‚  âœ“ Easy to understand\n",
    "   â””â”€ Cons:\n",
    "      âœ— Poor accuracy\n",
    "      âœ— No temporal context\n",
    "      âœ— Not suitable for real STT\n",
    "\n",
    "ðŸ–¥ï¸  CNN + MelSpectrogram\n",
    "   â”œâ”€ Architecture: 2 conv layers + FC layers\n",
    "   â”œâ”€ Temporal Modeling: Local (convolutional kernels)\n",
    "   â”œâ”€ Best For: Fast feature extraction\n",
    "   â”œâ”€ Pros:\n",
    "   â”‚  âœ“ Faster than RNNs\n",
    "   â”‚  âœ“ Good local feature learning\n",
    "   â”‚  âœ“ Moderate memory usage\n",
    "   â””â”€ Cons:\n",
    "      âœ— Limited long-range dependencies\n",
    "      âœ— Fixed receptive field\n",
    "      âœ— Medium accuracy\n",
    "\n",
    "ðŸ”„ LSTM + MelSpectrogram\n",
    "   â”œâ”€ Architecture: 2-layer LSTM\n",
    "   â”œâ”€ Temporal Modeling: Long-range (forward direction)\n",
    "   â”œâ”€ Best For: Balanced accuracy/speed\n",
    "   â”œâ”€ Pros:\n",
    "   â”‚  âœ“ Handles long sequences\n",
    "   â”‚  âœ“ Stable gradient flow\n",
    "   â”‚  âœ“ Industry standard\n",
    "   â””â”€ Cons:\n",
    "      âœ— Slower than GRU/CNN\n",
    "      âœ— More parameters than GRU\n",
    "      âœ— Cannot see future context\n",
    "\n",
    "âš¡ GRU + MelSpectrogram\n",
    "   â”œâ”€ Architecture: 2-layer GRU\n",
    "   â”œâ”€ Temporal Modeling: Long-range (forward direction)\n",
    "   â”œâ”€ Best For: Fast RNN training\n",
    "   â”œâ”€ Pros:\n",
    "   â”‚  âœ“ Faster than LSTM (~25%)\n",
    "   â”‚  âœ“ Fewer parameters\n",
    "   â”‚  âœ“ Similar accuracy to LSTM\n",
    "   â””â”€ Cons:\n",
    "      âœ— Slightly less expressive\n",
    "      âœ— Cannot see future context\n",
    "      âœ— Rare in modern STT\n",
    "\n",
    "â­ BiLSTM + MelSpectrogram\n",
    "   â”œâ”€ Architecture: 2-layer Bidirectional LSTM\n",
    "   â”œâ”€ Temporal Modeling: Long-range (both directions)\n",
    "   â”œâ”€ Best For: Maximum accuracy (offline STT)\n",
    "   â”œâ”€ Pros:\n",
    "   â”‚  âœ“ BEST accuracy for offline tasks\n",
    "   â”‚  âœ“ Sees past AND future context\n",
    "   â”‚  âœ“ Longest effective receptive field\n",
    "   â””â”€ Cons:\n",
    "      âœ— 2x slower than LSTM\n",
    "      âœ— 2x memory than LSTM\n",
    "      âœ— Cannot be used for streaming\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS FOR YOUR USE CASE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "ðŸŽ¯ CHOOSE BiLSTM IF:\n",
    "   â€¢ You need maximum accuracy\n",
    "   â€¢ Processing is offline (not real-time)\n",
    "   â€¢ Computational resources are available\n",
    "   â†’ BEST for: Batch speech transcription, research\n",
    "\n",
    "ðŸŽ¯ CHOOSE GRU IF:\n",
    "   â€¢ You want LSTM-like performance but faster\n",
    "   â€¢ You have limited GPU memory\n",
    "   â€¢ You need quick prototyping\n",
    "   â†’ BEST for: Real-time systems with constraints\n",
    "\n",
    "ðŸŽ¯ CHOOSE LSTM IF:\n",
    "   â€¢ You want industry-standard stability\n",
    "   â€¢ You need long-range dependency modeling\n",
    "   â€¢ You have balanced resources\n",
    "   â†’ BEST for: Production deployments\n",
    "\n",
    "ðŸŽ¯ CHOOSE CNN IF:\n",
    "   â€¢ You need very fast inference\n",
    "   â€¢ Latency is critical (streaming)\n",
    "   â€¢ You have very limited resources\n",
    "   â†’ BEST for: Edge devices, real-time streaming\n",
    "\n",
    "ðŸŽ¯ CHOOSE MLP ONLY FOR:\n",
    "   â€¢ Testing the data pipeline\n",
    "   â€¢ Understanding the problem\n",
    "   â€¢ Benchmarking\n",
    "   â†’ AVOID for: Actual STT tasks\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING EFFICIENCY METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate efficiency\n",
    "for model_name in [\"MLP + MFCC\", \"CNN + MelSpectrogram\", \"LSTM + MelSpectrogram\", \n",
    "                    \"GRU + MelSpectrogram\", \"BiLSTM + MelSpectrogram\"]:\n",
    "    metrics = comparator.results[model_name]\n",
    "    total_time = sum(metrics['train_times'])\n",
    "    final_loss = metrics['train_losses'][-1] if metrics['train_losses'] else 0\n",
    "    params = metrics['param_count']\n",
    "    \n",
    "    # Efficiency metrics\n",
    "    loss_per_second = final_loss / total_time if total_time > 0 else 0\n",
    "    params_per_second = params / total_time if total_time > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Total Training Time:  {total_time:.1f}s\")\n",
    "    print(f\"  Final Loss:           {final_loss:.4f}\")\n",
    "    print(f\"  Parameters:           {params:,}\")\n",
    "    print(f\"  Loss Reduction/sec:   {loss_per_second:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bc429",
   "metadata": {},
   "source": [
    "## 14. Save Results and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dataframe\n",
    "summary_data = []\n",
    "\n",
    "for model_name in [\"MLP + MFCC\", \"CNN + MelSpectrogram\", \"LSTM + MelSpectrogram\", \n",
    "                    \"GRU + MelSpectrogram\", \"BiLSTM + MelSpectrogram\"]:\n",
    "    metrics = comparator.results[model_name]\n",
    "    total_time = sum(metrics['train_times'])\n",
    "    initial_loss = metrics['train_losses'][0] if metrics['train_losses'] else 0\n",
    "    final_loss = metrics['train_losses'][-1] if metrics['train_losses'] else 0\n",
    "    improvement = ((initial_loss - final_loss) / initial_loss * 100) if initial_loss > 0 else 0\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Parameters': metrics['param_count'],\n",
    "        'Total Time (s)': round(total_time, 1),\n",
    "        'Avg Time/Epoch (s)': round(total_time / len(metrics['train_times']), 1),\n",
    "        'Initial Loss': round(initial_loss, 4),\n",
    "        'Final Loss': round(final_loss, 4),\n",
    "        'Improvement (%)': round(improvement, 1)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLETE SUMMARY TABLE\")\n",
    "print(\"=\" * 80)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv('training_summary.csv', index=False)\n",
    "print(\"\\nâœ“ Summary saved to 'training_summary.csv'\")\n",
    "\n",
    "# Save metrics as JSON\n",
    "import json\n",
    "metrics_dict = {}\n",
    "for model_name, metrics in comparator.results.items():\n",
    "    metrics_dict[model_name] = {\n",
    "        'param_count': int(metrics['param_count']),\n",
    "        'epochs': metrics['epochs'],\n",
    "        'train_losses': [float(x) for x in metrics['train_losses']],\n",
    "        'train_times': [float(x) for x in metrics['train_times']]\n",
    "    }\n",
    "\n",
    "with open('metrics.json', 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=2)\n",
    "print(\"âœ“ Metrics saved to 'metrics.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING AND EVALUATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  â€¢ model_comparison.png - Visual comparison of all models\")\n",
    "print(\"  â€¢ training_summary.csv - Summary metrics table\")\n",
    "print(\"  â€¢ metrics.json - Detailed metrics for further analysis\")\n",
    "print(\"  â€¢ *_ctc.pth - Trained model weights\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
